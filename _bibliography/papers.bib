---
---

@string{aps = {American Physical Society,}}

@article{RONG2025100277,
title = {Federated Large Domain Model System},
journal = {Blockchain: Research and Applications},
volume = {6},
number = {3},
pages = {100277},
year = {2025},
issn = {2096-7209},
doi = {https://doi.org/10.1016/j.bcra.2025.100277},
url = {https://www.sciencedirect.com/science/article/pii/S2096720925000041},
author = {Chunming Rong and Jungwon Seo and Zihan Zhao and Ferhat Ozgur Catak and Jiahui Geng and Martin Gilje Jaatun},
keywords = {Foundation model, ActivityPub, Large language model, Cloud computing, Blockchain},
abstract = {As organizations increasingly seek to build Foundation Models (FMs) using their own proprietary data, many are adopting private and in-house cloud infrastructures (often in addition to public clouds) to address concerns over cost, data privacy, and data sovereignty. However, these isolated private clouds frequently lack interoperability, creating barriers to cross-institutional collaboration, which is vital for training robust Domain-Specific Foundation Models (DSFMs) that rely on large and diverse datasets. Additionally, underutilized resources in private clouds lead to significant global energy inefficiencies. In this paper, we propose the Federated Large Domain Model System (FLDMS), a conceptual framework designed to facilitate collaborative foundation model development across multiple private cloud environments. We review the necessary enabling technologies, including decentralized protocols for data privacy and Large Language Models (LLMs) for automated orchestration, and present a high-level system design demonstrating how these components can be integrated. By enabling secure and efficient cross-organization cooperation, FLDMS provides a blueprint for building DSFMs while addressing the inefficiencies inherent in siloed private cloud systems.}
}

@article{ZHAO2025101683,
title = {WMPA-ConvBERT-BM: A hybrid deep learning model optimized by whale-marine predator algorithm for IoT-enabled malicious URL detection},
journal = {Internet of Things},
volume = {33},
pages = {101683},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101683},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525001970},
author = {Zihan Zhao and Yulin Zhu and Shilong Zhang and Amr Tolba and Osama Alfarraj and Keping Yu},
keywords = {Deep learning in cybersecurity, Malicious URLs detection, Hybrid deep learning, Cybersecurity in Internet of Things (IoT), Intelligent Optimization Algorithms (IOAs)},
abstract = {The increasing prevalence of malicious Uniform Resource Locators (URLs) in Internet of Things (IoT) environments poses a significant threat to network security. To address this challenge, we propose WMPA-ConvBERT-BM, a novel hybrid deep learning architecture that integrates ConvBERT and a multi-head attention-enhanced bidirectional Gated Recurrent Unit to effectively capture both semantic and structural features from URLs. The model utilizes a dual embedding strategy combining word-level and character-level representations for enriched multi-granular input. Furthermore, we introduce a Whale-Marine Predator Algorithm (WMPA), a hybrid intelligent optimization algorithm designed to adaptively search for optimal learning rates during training, enhancing convergence and generalization. Comprehensive experiments conducted on a large-scale multi-class malicious URL dataset demonstrate that our model achieves state-of-the-art performance, attaining an accuracy of 97.6%, precision of 96.769%, recall of 97.344% and F1-score of 97.032%, outperforming existing baselines and optimization methods. Ablation studies validate the critical contributions of each component, and further comparisons show the superiority of WMPA over conventional intelligent optimization algorithms. Additionally, SHAP-based interpretability analysis reveals how integrated embeddings contribute to prediction decisions, offering transparency and insights into model behavior. Results show that our WMPA-ConvBERT-BM provides an effective and interpretable solution for robust malicious URL detection in IoT scenarios.}
}

@inproceedings{zhao2024resource,
  title={A Resource-efficient Text-to-Text Transfer Transformer Encoder-based Vertical Hybrid Model for Malicious URLs Detection},
  author={Zhao, Zihan and Chen, Jinhua and Messou, Franck Junior Aboya and Katabarwa, Robert and Yu, Keping},
  booktitle={2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{chen2024byzantine,
  title={A Byzantine-Fault-Tolerant Federated Learning Method Using Tree-Decentralized Network and Knowledge Distillation for Internet of Vehicles},
  author={Chen, Jinhua and Zhao, Zihan and Messou, Franck Junior Aboya and Katabarwa, Robert and Alfarraj, Osama and Yu, Keping and Guizani, Mohsen},
  booktitle={2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{chen2024enhancing,
  title={Enhancing Production Planning in the Internet of Vehicles: A Transformer-based Federated Reinforcement Learning Approach},
  author={Chen, Jinhua and Zhao, Zihan and Yu, Keping and Mumtaz, Shahid and Rodrigues, Joel JPC and Guizani, Mohsen and Sato, Takuro},
  booktitle={2024 IEEE 99th Vehicular Technology Conference (VTC2024-Spring)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{messou2024enhancing,
  title={Enhancing Short-Term Load Forecasting in Internet of Things: A Hybrid Attention-based CNN-BiLSTM with Data Augmentation Approach},
  author={Messou, Franck Junior Aboya and Chen, Jinhua and Katabarwa, Robert and Zhao, Zihan and Yu, Keping},
  booktitle={2024 IEEE 100th Vehicular Technology Conference (VTC2024-Fall)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@inproceedings{katabarwa2025fortifed,
  title={FortiFed-SP: Client-Side Defense Against Label-Flipping Attacks in Federated Learning},
  author={Katabarwa, Robert and Chen, Jinhua and Zhao, Zihan and Messou, Franck Junior Aboya and Yu, Keping},
  booktitle={2025 5th International Conference on Intelligent Communications and Computing (ICICC)},
  pages={302--306},
  year={2025},
  organization={IEEE}
}

